name: Fetch and Upload GitHub Audit Logs to BigQuery

on:
  workflow_dispatch:  # 手動での実行を有効化

permissions:  # 必要な権限を設定
  id-token: write
  contents: read

jobs:
  fetch-and-upload:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      # Workload Identity Federationを使用してGoogle Cloudに認証
      - id: 'auth'
        name: 'Authenticate to Google Cloud'
        uses: 'google-github-actions/auth@v1'
        with:
          workload_identity_provider: 'projects/55684806562/locations/global/workloadIdentityPools/gha-pool-git-export/providers/github'
          service_account: 'git-audit-gha-sa@miurak.iam.gserviceaccount.com'

      # Python環境のセットアップとBigQuery Pythonクライアントのインストール
      - name: Set up Python environment
        run: |
          python3 -m venv venv
          . venv/bin/activate
          pip install --upgrade pip
          pip install google-cloud-bigquery requests

      # 監査ログの取得とBigQueryへのアップロード
      - name: Fetch audit logs and upload to BigQuery
        env:
          GCP_PROJECT_ID: miurak
          BQ_DATASET: test
          BQ_TABLE: git_audit
          PERSONAL_ACCESS_TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN }}  # シークレットからトークンを取得
        run: |
          . venv/bin/activate

          # GitHub APIを使用して監査ログを取得
          echo "Fetching audit logs..."
          response=$(curl -H "Authorization: token $PERSONAL_ACCESS_TOKEN" \
                        -H "Accept: application/vnd.github.v3+json" \
                        "https://api.github.com/orgs/miurak-test/audit-log")

          # レスポンスをファイルに保存
          echo "$response" > audit_logs.json

          # レスポンス内容を確認（デバッグ用）
          echo "Fetched logs:"
          cat audit_logs.json

          # Pythonスクリプトを実行してBigQueryにデータをアップロード
          python3 script.py
