name: Fetch and Upload GitHub Audit Logs to BigQuery

on:
  workflow_dispatch:  # 手動実行も可能に

permissions:
  id-token: write  # Google Cloudの認証用トークンの発行を許可
  contents: read   # リポジトリの内容に読み取りアクセスを付与

jobs:
  fetch-and-upload:
    runs-on: ubuntu-latest  # 最新のUbuntu環境で実行

    env:
      GCP_PROJECT_ID: miurak  # GCPプロジェクトID
      BQ_DATASET: test         # BigQueryデータセット名
      BQ_TABLE: git_audit      # BigQueryテーブル名

    steps:
      - uses: actions/checkout@v4  # 最新バージョンを使用

      - id: 'auth'
        uses: 'google-github-actions/auth@v2'
        with:
          workload_identity_provider: 'projects/55684806562/locations/global/workloadIdentityPools/gha-pool-git-export/providers/github'
          service_account: 'git-audit-gha-sa@miurak.iam.gserviceaccount.com'

      - name: Clear old virtual environment
        run: |
          rm -rf venv

      - name: Set up Python environment
        run: |
          python3 -m venv venv
          . venv/bin/activate
          pip install --upgrade pip
          pip install google-cloud-bigquery requests jq

      - name: Download previous timestamp artifact
        id: download-timestamp
        run: |
          mkdir -p artifacts
          gh run download --name last_run_timestamp --dir artifacts || echo "1970-01-01T00:00:00Z" > artifacts/last_run_timestamp.txt

      - name: Read previous timestamp
        run: |
          last_run=$(cat artifacts/last_run_timestamp.txt)
          echo "Last fetch timestamp: $last_run"

      - name: Fetch all audit logs from GitHub
        env:
          PERSONAL_ACCESS_TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
        run: |
          . venv/bin/activate
          current_time=$(date --utc --iso-8601=seconds)
          echo "$current_time" > artifacts/last_run_timestamp.txt

          next_url="https://api.github.com/orgs/miurak-test/audit-log?phrase=created:$last_run&per_page=100"
          > app/audit_logs.json  # ログを初期化

          while [[ ! -z "$next_url" ]]; do
            echo "Fetching logs from: $next_url"
            response=$(curl -i -H "Authorization: token $PERSONAL_ACCESS_TOKEN" \
                             -H "Accept: application/vnd.github.v3+json" \
                             "$next_url")

            # データ部分をjqで正しく抽出し、ファイルに保存
            echo "$response" | sed -n '/^\[/{x;p;d;}; x' | jq '.[]' >> app/audit_logs.json

            # ページネーションのためのリンクを取得
            next_url=$(echo "$response" | grep -i '^link:' | sed -n 's/.*<\(.*\)>; rel="next".*/\1/p')
            sleep 2  # レート制限に考慮して少し待機
          done

      - name: Upload new timestamp artifact
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: last_run_timestamp
          path: artifacts/last_run_timestamp.txt

      - name: Run script to upload logs to BigQuery
        run: |
          . venv/bin/activate
          python3 app/script.py
