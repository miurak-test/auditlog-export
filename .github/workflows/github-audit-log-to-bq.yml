name: Fetch and Upload GitHub Audit Logs to BigQuery

on:
  workflow_dispatch:  # 手動実行も可能に

permissions:
  id-token: write  # Google Cloudの認証用トークンの発行を許可
  contents: read   # リポジトリの内容に読み取りアクセスを付与

jobs:
  fetch-and-upload:
    runs-on: ubuntu-latest  # 最新のUbuntu環境で実行

    env:
      GCP_PROJECT_ID: miurak  # GCPプロジェクトID
      BQ_DATASET: test         # BigQueryデータセット名
      BQ_TABLE: git_audit      # BigQueryテーブル名

    steps:
      - uses: actions/checkout@v4  # 最新バージョンを使用

      - id: 'auth'
        uses: 'google-github-actions/auth@v2'
        with:
          workload_identity_provider: 'projects/55684806562/locations/global/workloadIdentityPools/gha-pool-git-export/providers/github'
          service_account: 'git-audit-gha-sa@miurak.iam.gserviceaccount.com'

      - name: Clear old virtual environment
        run: |
          rm -rf venv

      - name: Set up Python environment
        run: |
          python3 -m venv venv
          . venv/bin/activate
          pip install --upgrade pip
          pip install google-cloud-bigquery requests jq

      - name: Download previous timestamp artifact
        id: download-timestamp
        run: |
          mkdir -p artifacts
          gh run download --name last_run_timestamp --dir artifacts || echo "1970-01-01T00:00:00Z" > artifacts/last_run_timestamp.txt

      - name: Read previous timestamp
        run: |
          last_run=$(cat artifacts/last_run_timestamp.txt)
          echo "Last fetch timestamp: $last_run"

          - name: Fetch all audit logs from GitHub
          env:
            PERSONAL_ACCESS_TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
          run: |
            . venv/bin/activate
            current_time=$(date --utc --iso-8601=seconds)
            echo "$current_time" > artifacts/last_run_timestamp.txt  # 新しいタイムスタンプを保存
      
            # ログを初期化
            echo "" > app/audit_logs.json
      
            next_url="https://api.github.com/orgs/miurak-test/audit-log?phrase=created:$last_run&per_page=100"
            while [[ ! -z "$next_url" ]]; do
              echo "Fetching logs from: $next_url"
              response=$(curl -s -H "Authorization: token $PERSONAL_ACCESS_TOKEN" \
                               -H "Accept: application/vnd.github.v3+json" \
                               "$next_url")
      
              # レスポンスの内容を一時保存してデバッグ用に確認
              echo "$response" > temp_response.json
      
              # jqを使ってJSON形式が正しいかチェックし、正しくない場合エラーを出力して終了
              if ! echo "$response" | jq . > /dev/null 2>&1; then
                echo "Invalid JSON format in response:"
                cat temp_response.json
                exit 1
              fi
      
              # 取得したレスポンスからログ部分だけを抽出し、追加する
              echo "$response" | jq '.[]' >> app/audit_logs.json
      
              # ページネーションのための次のリンクを取得
              next_url=$(curl -s -I -H "Authorization: token $PERSONAL_ACCESS_TOKEN" "$next_url" | grep -i '^link:' | sed -n 's/.*<\(.*\)>; rel="next".*/\1/p')
      
              sleep 2  # レート制限に配慮して少し待機
            done

      - name: Run script to upload logs to BigQuery
        run: |
          . venv/bin/activate
          python3 app/script.py
        continue-on-error: false

      - name: Upload new timestamp artifact
        if: success()  # 成功時のみアップロード
        uses: actions/upload-artifact@v4
        with:
          name: last_run_timestamp
          path: artifacts/last_run_timestamp.txt
