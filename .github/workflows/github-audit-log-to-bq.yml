name: Fetch and Upload GitHub Audit Logs to BigQuery

on:
  schedule:
    - cron: '0 * * * *'  # 毎時実行
  workflow_dispatch:  # 手動での実行を有効化

jobs:
  fetch-and-upload:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      # Workload Identity Federationを使用してGoogle Cloudに認証
      - id: 'auth'
        name: 'Authenticate to Google Cloud'
        uses: 'google-github-actions/auth@v1'
        with:
          workload_identity_provider: 'projects/55684806562/locations/global/workloadIdentityPools/gha-pool-git-export/providers/github'
          service_account: 'git-audit-gha-sa@miurak.iam.gserviceaccount.com'

      # Python環境のセットアップとBigQuery Pythonクライアントのインストール
      - name: Set up Python environment
        run: |
          python3 -m venv venv
          . venv/bin/activate
          pip install --upgrade pip
          pip install google-cloud-bigquery requests

      - name: Fetch audit logs and upload to BigQuery
        env:
          GCP_PROJECT_ID: miurak
          BQ_DATASET: test
          BQ_TABLE: git_audit
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          . venv/bin/activate

          # GitHub APIを使用して監査ログを取得
          echo "Fetching audit logs..."
          response=$(curl -H "Authorization: token $GITHUB_TOKEN" \
                        -H "Accept: application/vnd.github.v3+json" \
                        "https://api.github.com/orgs/YOUR_ORG_NAME/audit-log")
          
          # レスポンスをファイルに保存
          echo "$response" > audit_logs.json
          
          # ルートディレクトリに配置されたPythonスクリプトを実行
          python3 script.py
