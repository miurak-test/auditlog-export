name: Fetch and Upload GitHub Audit Logs to BigQuery

on:
  workflow_dispatch:  # 手動でワークフローを実行できるように設定

permissions:
  id-token: write  # Google Cloud認証のためのトークン書き込み権限を付与
  contents: read  # リポジトリの内容に読み取りアクセスを付与

jobs:
  fetch-and-upload:
    runs-on: ubuntu-latest  # Ubuntuの最新環境でジョブを実行

    env:
      GCP_PROJECT_ID: miurak  # Google CloudのプロジェクトID
      BQ_DATASET: test  # BigQueryのデータセット名
      BQ_TABLE: git_audit  # BigQueryのテーブル名

    steps:
      - uses: actions/checkout@v4  # リポジトリの内容をチェックアウトして取得

      - id: 'auth'
        uses: 'google-github-actions/auth@v2'  # Google Cloudに認証するためのステップ
        with:
          workload_identity_provider: 'projects/55684806562/locations/global/workloadIdentityPools/gha-pool-git-export/providers/github'  # Workload Identity Federationの設定
          service_account: 'git-audit-gha-sa@miurak.iam.gserviceaccount.com'  # 使用するサービスアカウント

      - name: Clear old virtual environment
        run: |
          rm -rf venv  # 以前の仮想環境（venv）があれば削除

      - name: Set up Python environment
        run: |
          python3 -m venv venv  # 新しい仮想環境を作成
          . venv/bin/activate  # 仮想環境を有効化
          pip install --upgrade pip  # pipを最新にアップグレード
          pip install google-cloud-bigquery requests jq  # 必要なパッケージをインストール

      - name: Download previous timestamp artifact
        id: download-timestamp
        run: |
          mkdir -p artifacts  # アーティファクト保存用ディレクトリを作成
          # 前回の実行時刻（タイムスタンプ）をダウンロード。存在しない場合は1970年1月1日をデフォルトに設定
          gh run download --name last_run_timestamp --dir artifacts || echo "1970-01-01T00:00:00Z" > artifacts/last_run_timestamp.txt

      - name: Read previous timestamp
        run: |
          last_run=$(cat artifacts/last_run_timestamp.txt)  # ダウンロードしたタイムスタンプを読み込み
          echo "Last fetch timestamp: $last_run"  # 最終実行時刻を出力

      - name: Fetch all audit logs from GitHub
        env:
          PERSONAL_ACCESS_TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN }}  # GitHubのパーソナルアクセストークンを使用
        run: |
          . venv/bin/activate  # 仮想環境を有効化
          current_time=$(date --utc --iso-8601=seconds)  # 現在時刻をUTCで取得
          echo "$current_time" > artifacts/last_run_timestamp.txt  # 新しいタイムスタンプを保存

          rm -rf app/audit_logs  # 以前のログをクリア
          mkdir -p app/audit_logs  # ログ保存用ディレクトリを作成

          next_url="https://api.github.com/orgs/miurak-test/audit-log?phrase=created:$last_run&per_page=100"  # GitHub監査ログAPIを呼び出す初期URL
          total_logs=0  # 取得したログの合計件数を初期化

          while [[ ! -z "$next_url" ]]; do  # ページネーションがある限り次のページを取得
            echo "Fetching logs from: $next_url"  # 次のURLからログを取得
            response=$(curl -s -H "Authorization: token $PERSONAL_ACCESS_TOKEN" \
                             -H "Accept: application/vnd.github.v3+json" \
                             "$next_url")  # GitHub APIから監査ログを取得

            logs_count=$(echo "$response" | jq '. | length')  # 取得したログの件数をカウント
            echo "Fetched $logs_count logs."  # 取得件数を出力
            total_logs=$((total_logs + logs_count))  # 合計ログ数に加算
            echo "Total logs so far: $total_logs"  # これまでの合計ログ数を出力

            echo "$response" > "app/audit_logs/log_$total_logs.json"  # 取得したログをファイルに保存

            next_url=$(curl -s -I -H "Authorization: token $PERSONAL_ACCESS_TOKEN" "$next_url" | grep -i '^link:' | sed -n 's/.*<\(.*\)>; rel="next".*/\1/p')  # 次のページURLを取得

            sleep 2  # レート制限に配慮して少し待機
          done

          echo "Finished fetching logs. Total logs fetched: $total_logs"  # 取得終了後のログ数を出力

      - name: Upload new timestamp artifact
        uses: actions/upload-artifact@v4  # 新しいタイムスタンプをアーティファクトとしてアップロード
        with:
          name: last_run_timestamp  # アーティファクトの名前
          path: artifacts/last_run_timestamp.txt  # アップロードするファイルのパス

      - name: Run script to upload logs to BigQuery
        run: |
          . venv/bin/activate  # 仮想環境を有効化
          python3 app/script.py  # BigQueryにアップロードするPythonスクリプトを実行
