name: Fetch and Upload GitHub Audit Logs to BigQuery

on:
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

jobs:
  fetch-and-upload:
    runs-on: ubuntu-latest

    env:
      GCP_PROJECT_ID: miurak
      BQ_DATASET: test
      BQ_TABLE: git_audit

    steps:
      - uses: actions/checkout@v4

      - id: 'auth'
        uses: 'google-github-actions/auth@v2'
        with:
          workload_identity_provider: 'projects/55684806562/locations/global/workloadIdentityPools/gha-pool-git-export/providers/github'
          service_account: 'git-audit-gha-sa@miurak.iam.gserviceaccount.com'

      - name: Clear old virtual environment
        run: |
          rm -rf venv

      - name: Set up Python environment
        run: |
          python3 -m venv venv
          . venv/bin/activate
          pip install --upgrade pip
          pip install google-cloud-bigquery requests jq

      - name: Download previous timestamp artifact
        id: download-timestamp
        run: |
          mkdir -p artifacts
          gh run download --name last_run_timestamp --dir artifacts || echo "1970-01-01T00:00:00Z" > artifacts/last_run_timestamp.txt

      - name: Read previous timestamp
        run: |
          last_run=$(cat artifacts/last_run_timestamp.txt)
          echo "Last fetch timestamp: $last_run"

      - name: Fetch all audit logs from GitHub
        env:
          PERSONAL_ACCESS_TOKEN: ${{ secrets.PERSONAL_ACCESS_TOKEN }}
        run: |
          . venv/bin/activate
          current_time=$(date --utc --iso-8601=seconds)
          echo "$current_time" > artifacts/last_run_timestamp.txt

          rm -rf app/audit_logs  # Clear any previous logs
          mkdir -p app/audit_logs

          next_url="https://api.github.com/orgs/miurak-test/audit-log?phrase=created:$last_run&per_page=100"
          total_logs=0

          while [[ ! -z "$next_url" ]]; do
            echo "Fetching logs from: $next_url"
            response=$(curl -s -H "Authorization: token $PERSONAL_ACCESS_TOKEN" \
                             -H "Accept: application/vnd.github.v3+json" \
                             "$next_url")

            logs_count=$(echo "$response" | jq '. | length')
            echo "Fetched $logs_count logs."
            total_logs=$((total_logs + logs_count))
            echo "Total logs so far: $total_logs"

            echo "$response" > "app/audit_logs/log_$total_logs.json"

            next_url=$(curl -s -I -H "Authorization: token $PERSONAL_ACCESS_TOKEN" "$next_url" | grep -i '^link:' | sed -n 's/.*<\(.*\)>; rel="next".*/\1/p')

            sleep 2
          done

          echo "Finished fetching logs. Total logs fetched: $total_logs"

      - name: Upload new timestamp artifact
        uses: actions/upload-artifact@v4
        with:
          name: last_run_timestamp
          path: artifacts/last_run_timestamp.txt

      - name: Run script to upload logs to BigQuery
        run: |
          . venv/bin/activate
          python3 app/script.py
